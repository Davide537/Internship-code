{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg \n",
    "# Pkg.instantiate()\n",
    "Pkg.activate(\".\")  # activate the environment for this notebook\n",
    "# load the packages\n",
    "using Flux, Dates, BSON, Measures, JLD2, Noise, JSON, Plots\n",
    "using Printf, Statistics, ProgressMeter, ParameterSchedulers, LaTeXStrings\n",
    "using ParameterSchedulers: Stateful , Optimisers\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbaf18",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbabb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default(linewidth = 1)\n",
    "\n",
    "@load \"LSTM plots/results_LSTM.jld2\" results train_results\n",
    "\n",
    "# Colors per epoch\n",
    "epoch_list = [100, 200, 300, 400]\n",
    "color_map = Dict(e => i for (i, e) in enumerate(epoch_list))\n",
    "\n",
    "# Function to collect mean and std of MSE across alts, skipping horizon_u=5\n",
    "function collect_mean_std_over_alt_skip5(branch_results, horizon_t, epochs)\n",
    "    alts = collect(keys(branch_results[horizon_t][epochs]))\n",
    "    horizon_us_all = sort(collect(keys(branch_results[horizon_t][epochs][alts[1]])))\n",
    "    \n",
    "    # Skip horizon_u = 5\n",
    "    horizon_us = filter(x -> x != 5, horizon_us_all)\n",
    "    \n",
    "    mean_over_alts = Float64[]\n",
    "    std_over_alts  = Float64[]\n",
    "    \n",
    "    for h in horizon_us\n",
    "        vals = [branch_results[horizon_t][epochs][alt][h][1] for alt in alts]\n",
    "        push!(mean_over_alts, mean(vals))\n",
    "        push!(std_over_alts, std(vals))\n",
    "    end\n",
    "    \n",
    "    return horizon_us, mean_over_alts, std_over_alts\n",
    "end\n",
    "\n",
    "for branch in sort(collect(keys(results)))\n",
    "    branch_results = results[branch]\n",
    "\n",
    "    savepath = \"plots_branch_$branch\"\n",
    "    isdir(savepath) || mkdir(savepath)\n",
    "\n",
    "    for horizon_t in sort(collect(keys(branch_results)))\n",
    "\n",
    "        plt = plot(\n",
    "            title = L\"Branch %$(branch), Training Horizon $s_t$ = %$(horizon_t)\",\n",
    "            xlabel = L\"Unrolling Horizon $s_u$\",\n",
    "            ylabel = \"Loss\",\n",
    "            legend = :topright\n",
    "        )\n",
    "\n",
    "        for epochs in sort(collect(keys(branch_results[horizon_t])))\n",
    "\n",
    "            hrz_u, mse_mean, mse_std = collect_mean_std_over_alt_skip5(branch_results, horizon_t, epochs)\n",
    "\n",
    "            plot!(\n",
    "                plt, \n",
    "                hrz_u, mse_mean, \n",
    "                markersize = 3.5, marker = :diamond,\n",
    "                label = L\"n_{epochs}=%$epochs\",\n",
    "                color = color_map[epochs]\n",
    "            )\n",
    "\n",
    "            plot!(\n",
    "                plt, \n",
    "                hrz_u, mse_mean, \n",
    "                markersize = 3.5, marker =:diamond,   \n",
    "                label = \"\", \n",
    "                color = color_map[epochs],\n",
    "                ribbon = mse_std, fillalpha = 0.12\n",
    "            )\n",
    "\n",
    "        end\n",
    "\n",
    "        savefig(joinpath(savepath, \"mse_vs_unroll_t_$(horizon_t)_meanAlt.png\"))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default(linewidth = 1, markersize = 3.5)\n",
    "\n",
    "@load \"LSTM plots/results_LSTM.jld2\" results train_results\n",
    "\n",
    "# Colors per epoch\n",
    "epoch_list = [100, 200, 300, 400]\n",
    "color_map = Dict(e => i for (i,e) in enumerate(epoch_list))\n",
    "\n",
    "for branch in sort(collect(keys(train_results)))\n",
    "    branch_train = train_results[branch]\n",
    "    savepath = \"train_plots_branch_$branch\"\n",
    "    isdir(savepath) || mkdir(savepath)\n",
    "\n",
    "    # Collect horizon_ts\n",
    "    horizon_ts = sort(collect(keys(branch_train)))\n",
    "\n",
    "    # ---- Plot: Training Loss (mean ± std over alts) ----\n",
    "    plt_loss = plot(\n",
    "        title = L\"Branch %$branch, Training Loss vs Training Horizon $s_t$\",\n",
    "        xlabel = L\"Training Horizon $s_t$\",\n",
    "        ylabel = \"Training Loss\",\n",
    "        legend = :topright\n",
    "    )\n",
    "\n",
    "    for epoch in epoch_list\n",
    "        mean_loss = Float64[]\n",
    "        std_loss  = Float64[]\n",
    "        horizon_filtered = Int[]\n",
    "\n",
    "        for horizon_t in horizon_ts\n",
    "            if haskey(branch_train[horizon_t], epoch)\n",
    "                alts = collect(keys(branch_train[horizon_t][epoch]))\n",
    "                vals = [branch_train[horizon_t][epoch][alt][:loss_stat_t][1] for alt in alts]\n",
    "                push!(mean_loss, mean(vals))\n",
    "                push!(std_loss, std(vals))\n",
    "                push!(horizon_filtered, horizon_t)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        plot!(\n",
    "            plt_loss,\n",
    "            horizon_filtered, mean_loss,\n",
    "            markersize = 3.5, marker =:diamond,   \n",
    "            label = L\"n_{epochs}=%$epoch\", \n",
    "            color = color_map[epoch],\n",
    "        )\n",
    "\n",
    "        plot!(\n",
    "            plt_loss,\n",
    "            horizon_filtered, mean_loss,\n",
    "            markersize = 3.5, marker =:diamond,   \n",
    "            label = \"\",\n",
    "            color = color_map[epoch],\n",
    "            ribbon = std_loss, fillalpha = 0.12\n",
    "        )\n",
    "\n",
    "    end\n",
    "\n",
    "    savefig(joinpath(savepath, \"train_loss_vs_horizon_meanAlt.png\"))\n",
    "\n",
    "    # ---- Plot: Training Time (mean ± std over alts) ----\n",
    "    plt_time = plot(\n",
    "        title = L\"Branch %$branch, Computational Time vs Training Horizon $s_t$\",\n",
    "        xlabel = L\"Training Horizon $s_t$\",\n",
    "        ylabel = \"Computational Time [s]\",\n",
    "        legend = :topright\n",
    "    )\n",
    "\n",
    "    for epoch in epoch_list\n",
    "        mean_time = Float64[]\n",
    "        std_time  = Float64[]\n",
    "        horizon_filtered = Int[]\n",
    "\n",
    "        for horizon_t in horizon_ts\n",
    "            if haskey(branch_train[horizon_t], epoch)\n",
    "                alts = collect(keys(branch_train[horizon_t][epoch]))\n",
    "                vals = [branch_train[horizon_t][epoch][alt][:train_time] for alt in alts]\n",
    "                push!(mean_time, mean(vals))\n",
    "                push!(std_time, std(vals))\n",
    "                push!(horizon_filtered, horizon_t)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        plot!(\n",
    "            plt_time,\n",
    "            horizon_filtered, mean_time,\n",
    "            markersize = 3.5, marker =:diamond,   \n",
    "            label = L\"n_{epochs}=%$epoch\", yaxis=:log10, xaxis=:log10,\n",
    "            color = color_map[epoch],\n",
    "        )\n",
    "\n",
    "        plot!(\n",
    "            plt_time,\n",
    "            horizon_filtered, mean_time,\n",
    "            markersize = 3.5, marker =:diamond,   \n",
    "            label = \"\",\n",
    "            color = color_map[epoch],\n",
    "            ribbon = std_time, fillalpha = 0.12,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    savefig(joinpath(savepath, \"train_time_vs_horizon_meanAlt.png\"))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f984d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"loss_alt_comp_storms_b1.jld2\" loss  \n",
    "\n",
    "horizons = [60, 50, 40, 30, 20]\n",
    "alts = [0, 1, 2]\n",
    "epochsL = [100, 200, 300, 400]\n",
    "storms = [1, 2, 3]\n",
    "\n",
    "for ep in epochsL\n",
    "    \n",
    "    plt = plot(\n",
    "        title = \"Branch 1, Unroll Loss vs Horizon (epochs = $ep)\",\n",
    "        xlabel = \"Horizon\",\n",
    "        ylabel = \"Loss\",\n",
    "        legend = :topright,\n",
    "        lw = 1,\n",
    "        xticks = horizons,\n",
    "    )\n",
    "\n",
    "    for alt in alts\n",
    "        \n",
    "        # compute mean loss across storms for each horizon\n",
    "        mean_losses = [\n",
    "            mean([ loss[(h, alt, ep, s)][1] for s in storms ])\n",
    "            for h in horizons\n",
    "        ]\n",
    "\n",
    "        plot!(\n",
    "            horizons,\n",
    "            mean_losses,\n",
    "            label = \"alt = $alt\",\n",
    "            marker = :diamond,\n",
    "            markersize = 3.5,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    display(plt)\n",
    "\n",
    "    # Optional save\n",
    "    png(\"loss_vs_horizon_epoch$(ep)_mean_storms_b1.png\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d57a18",
   "metadata": {},
   "source": [
    "# FRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b18dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "@load \"matrixtrain.jld2\" train_stat\n",
    "@load \"matrixunroll.jld2\" unroll_stat\n",
    "@load \"bestmodel_t.jld2\" best_stat_t\n",
    "@load \"bestmodel_u.jld2\" best_stat_u\n",
    "\n",
    "trials = size(train_stat,1)\n",
    "\n",
    "data=load(\"Dataset/model_0d_lake_sep.jld2\")\n",
    "\n",
    "for branch in 1:2\n",
    "    X, Y, time  = collect_data(data, branch, noise_param = 0.1)\n",
    "    x0 = X[:,1]\n",
    "    ext_forc = X[1+branch:end,:]\n",
    "    model_r = best_stat_u[branch][1]\n",
    "    outputs , mse = unroll(model_r, x0, ext_forc, Y, branch)\n",
    "    plot_unroll(outputs, Y, time, branch)\n",
    "    # Index of best training trial\n",
    "    best_train_idx = Int(best_stat_t[branch][2][end])\n",
    "    # Index of best unroll trial\n",
    "    best_unroll_idx = Int(best_stat_u[branch][2][end])\n",
    "\n",
    "    println(\"\\nBranch $branch\")\n",
    "    @show best_stat_u[branch][2]\n",
    "    println(\"Best training trial: $best_train_idx\")\n",
    "    println(\"  Train metrics  : \", train_stat[best_train_idx, branch])\n",
    "    println(\"  Unroll metrics : \", unroll_stat[best_train_idx, branch])\n",
    "\n",
    "    println(\"Best unroll trial: $best_unroll_idx\")\n",
    "    println(\"  Train metrics  : \", train_stat[best_unroll_idx, branch])\n",
    "    println(\"  Unroll metrics : \", unroll_stat[best_unroll_idx, branch])\n",
    "end\n",
    "\n",
    "threshold = 1\n",
    "fail_count = zeros(Int, 2)\n",
    "\n",
    "# Arrays to store mean and std per branch (MSE only)\n",
    "mean_train  = zeros(2)\n",
    "std_train   = zeros(2)\n",
    "mean_unroll = zeros(2)\n",
    "std_unroll  = zeros(2)\n",
    "\n",
    "for branch in 1:2\n",
    "    p = plot(layout = (1,1), size = (500,500), right_margin = 5mm,\n",
    "             titlefontsize = 15, legend_column = -1, legend = :outerbottom, \n",
    "             legendfontsize = 8)\n",
    "\n",
    "    # valid entries based on unroll MSE only\n",
    "    valid_mask = unroll_stat[:, branch] .< threshold\n",
    "    fail_count[branch] = count(!, valid_mask)\n",
    "\n",
    "    # Extract MSE only\n",
    "    train_vals  = train_stat[:, branch]\n",
    "    unroll_vals = unroll_stat[:, branch]\n",
    "\n",
    "    # Filter valid trials\n",
    "    train_x = (1:trials)[valid_mask]\n",
    "    train_y = train_vals[valid_mask]\n",
    "    unroll_x = train_x\n",
    "    unroll_y = unroll_vals[valid_mask]\n",
    "\n",
    "    # Compute statistics\n",
    "    mean_train[branch]  = mean(train_y)\n",
    "    std_train[branch]   = std(train_y)\n",
    "    mean_unroll[branch] = mean(unroll_y)\n",
    "    std_unroll[branch]  = std(unroll_y)\n",
    "\n",
    "    # Legend text\n",
    "    legend_train  = @sprintf(\"μ=%.6f σ=%.6f\", mean_train[branch],  std_train[branch])\n",
    "    legend_unroll = @sprintf(\"μ=%.6f σ=%.6f\", mean_unroll[branch], std_unroll[branch])\n",
    "\n",
    "    # -------- Plot (only MSE) --------\n",
    "    scatter!(p, train_x, train_y,\n",
    "        title = \"Branch $branch — MSE\",\n",
    "        ylabel = \"MSE\",\n",
    "        ylim = (-0.05, threshold + 0.05),\n",
    "        markersize = 5, ma = 0.5,\n",
    "        label = \"Train MSE\\n$legend_train\")\n",
    "\n",
    "    scatter!(p, unroll_x, unroll_y,\n",
    "        markersize = 5, ma = 0.5,\n",
    "        label = \"Unroll MSE\\n$legend_unroll\")\n",
    "\n",
    "    display(p)\n",
    "end\n",
    "\n",
    "# Print failure counts\n",
    "println(\"Failures per branch:\")\n",
    "for branch in 1:2\n",
    "    println(\"Branch $branch — MSE failures: $(fail_count[branch])  ($(fail_count[branch]/trials))\")\n",
    "end\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
